import base64
import os
import requests
from bs4 import BeautifulSoup

# ================= CONFIG =================
WP_URL = "https://blog.mexc.com/wp-json/wp/v2/posts"
WP_USERNAME = os.getenv("WP_USERNAME")
WP_APP_PASSWORD = os.getenv("WP_APP_PASSWORD")
POST_ID = 304392  # ID b√†i Spur Protocol
TARGET_H2_TEXT = "Spur Protocol Quiz Answers Today for December 6, 2025"
CHECK_ANSWER = "D) DeFi and NFTS."

# find & replace
OLD_DATE = "December 6"
NEW_DATE = "December 7"


# ================ SCRAPE SITE ================
def scrape_quiz_site():
    url = "https://miningcombo.com/spur-protocol/"
    print(f"[+] Scraping quiz from {url}")
    r = requests.get(url, timeout=15, headers={"User-Agent": "Mozilla/5.0"})
    r.raise_for_status()
    soup = BeautifulSoup(r.text, "html.parser")

    ps = soup.find_all("p", class_="has-text-align-left")
    if not ps or len(ps) < 2:
        raise RuntimeError("‚ùå Kh√¥ng t√¨m th·∫•y ƒë·ªß th·∫ª <p class='has-text-align-left'>")

    question = None
    answer = None
    for p in ps:
        text = p.get_text(strip=True)
        if "Question:" in text:
            question = text.replace("Question:", "").strip()
        elif "Answer:" in text:
            answer = text.replace("Answer:", "").strip()

    if not question or not answer:
        raise RuntimeError("‚ùå Kh√¥ng tr√≠ch xu·∫•t ƒë∆∞·ª£c question ho·∫∑c answer")

    print("[+] Scraped question and answer")
    print("   Q:", question)
    print("   A:", answer)
    return question, answer


# ================ UPDATE POST ================
def update_post_after_h2(target_h2_text, question, answer):
    if not WP_USERNAME or not WP_APP_PASSWORD:
        raise RuntimeError("‚ö†Ô∏è Thi·∫øu repo secret: WP_USERNAME ho·∫∑c WP_APP_PASSWORD")

    token = base64.b64encode(f"{WP_USERNAME}:{WP_APP_PASSWORD}".encode()).decode("utf-8")
    headers = {
        "Authorization": f"Basic {token}",
        "User-Agent": "Mozilla/5.0",
        "Accept": "application/json"
    }

    # 1. Fetch current post
    url = f"{WP_URL}/{POST_ID}"
    response = requests.get(url, headers=headers, timeout=15)
    print("üîé Fetch status:", response.status_code)
    if response.status_code != 200:
        print("‚ùå Kh√¥ng l·∫•y ƒë∆∞·ª£c post:", response.text[:300])
        return

    post = response.json()
    old_content = post.get("content", {}).get("rendered", "")
    if not old_content:
        print("‚ùå Kh√¥ng th·∫•y content.rendered")
        return

    print("‚úçÔ∏è L·∫•y content.rendered, ƒë·ªô d√†i:", len(old_content))
    soup = BeautifulSoup(old_content, "html.parser")

    # 2. T√¨m <h2> kh·ªõp text
    h2_tag = soup.find("h2", string=lambda t: t and target_h2_text in t)
    if not h2_tag:
        print("‚ùå Kh√¥ng t√¨m th·∫•y H2 ph√π h·ª£p")
        print("Rendered snippet:", old_content[:400])
        return

    # 3. Xo√° to√†n b·ªô <p> sau H2 (ƒëang l√† Q/A c≈©)
    next_tag = h2_tag.find_next_sibling()
    removed = 0
    while next_tag and next_tag.name == "p":
        nxt = next_tag.find_next_sibling()
        next_tag.decompose()
        next_tag = nxt
        removed += 1
    print(f"[+] Removed {removed} <p> c≈© sau H2")

    # 4. T·∫°o ƒëo·∫°n Q/A m·ªõi
    p_tag = soup.new_tag("p")
    p_tag["style"] = "font-size:17px"

    strong_q = soup.new_tag("strong")
    strong_q.string = f"The question for {NEW_DATE}, 2025:"
    p_tag.append(strong_q)
    p_tag.append(f" {question}\n")

    strong_a_label = soup.new_tag("strong")
    strong_a_label.string = "Correct Answer:"
    p_tag.append(strong_a_label)
    p_tag.append(" ")

    strong_a = soup.new_tag("strong")
    strong_a.string = answer
    p_tag.append(strong_a)

    # 5. Ch√®n Q/A m·ªõi sau H2
    h2_tag.insert_after(p_tag)

    # 6. Find & replace ng√†y trong content
    new_content = str(soup).replace(OLD_DATE, NEW_DATE)
    print("[+] New content length:", len(new_content))

    # ---- UPDATE CONTENT ----
    payload = {"content": new_content, "status": "publish"}
    update = requests.post(url, headers=headers, json=payload, timeout=15)
    print("üöÄ Update content status:", update.status_code)

    if update.status_code != 200:
        print("‚ùå Error khi update content")
        return

    print("‚úÖ Content updated & published!")

    # ============================
    # UPDATE WP TITLE (NO SEO)
    # ============================

    updated_post = update.json()
    current_title = updated_post.get("title", {}).get("rendered", "")

    new_title = current_title.replace(OLD_DATE, NEW_DATE)

    title_payload = {
        "title": new_title
    }

    title_update = requests.post(url, headers=headers, json=title_payload, timeout=15)
    print("üìù Update Title status:", title_update.status_code)

    if title_update.status_code == 200:
        print("‚úÖ WP Post Title updated!")
    else:
        print("‚ö†Ô∏è Title update failed (content still OK)")


# ================ MAIN =================
if __name__ == "__main__":
    try:
        q, a = scrape_quiz_site()
        if a.strip() != CHECK_ANSWER.strip():
            print("‚úÖ Answer kh√°c CHECK_ANSWER -> Update ngay")
            update_post_after_h2(TARGET_H2_TEXT, q, a)
        else:
            print("‚ö†Ô∏è Answer tr√πng CHECK_ANSWER -> Kh√¥ng c·∫ßn update")
    except Exception as e:
        print("‚ùå L·ªói khi scrape ho·∫∑c update:", e)
